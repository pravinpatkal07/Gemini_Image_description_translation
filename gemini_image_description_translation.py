# -*- coding: utf-8 -*-
"""Gemini_Image_description_translation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CKVg_m-7u37OFkufcn4kY86OlwGh9uHl
"""

!sudo apt install espeak  # voice error
!pip install googletrans==4.0.0-rc1
!pip install pyttsx3
!pip install streamlit
!npm install localtunel   # look likes error but not error
!pip install google-generativeai  # Not required in google colab
!pip -q install pyngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# from PIL import Image
# import google.generativeai as genai
# import pyttsx3
# from googletrans import Translator
# 
# # Streamlit app
# st.title("AI Image Description & Translation")
# st.write("Upload an image and enter a prompt. The model will generate a description based on your prompt.")
# 
# uploaded_file = st.file_uploader("Choose an image...", type="jpg")
# user_prompt = st.text_input("Enter your prompt:", value="")
# 
# def generate_audio(i):
#     audio = pyttsx3.init()
#     audio.setProperty('rate', 150)
#     audio.setProperty('volume', 1.0)
#     voices = audio.getProperty('voices')
#     audio.setProperty('voice', voices[i].id)
#     audio.save_to_file(st.session_state.description, "1.mp3")
#     audio.runAndWait()
# 
# def change_language(language):
#     translator = Translator()
#     translated_text = translator.translate(st.session_state.description, dest=language)
#     return translated_text.text
# 
# if uploaded_file and user_prompt:
#     try:
#         if 'description' not in st.session_state:
#             api_key ="AIzaSyBIPridKAwHeYztM8MiBFeMk_DZCupjg2w"
#             genai.configure(api_key=api_key)
#             model = genai.GenerativeModel('gemini-1.5-flash')
#             st.session_state.img = Image.open(uploaded_file)
#             response = model.generate_content([user_prompt, st.session_state.img])
#             st.session_state.description = response.text
#         st.image(st.session_state.img, caption='Uploaded Image', use_column_width=True)
#         st.write(st.session_state.description)
#     except Exception as e:
#         st.error(f"Error processing the image: {e}")
# else:
#     if not uploaded_file:
#         st.write("No image file selected.")
#     if not user_prompt:
#         st.write("Please enter a prompt.")
# 
# voice_choice = st.selectbox("Choose a voice:", ["None", "Male", "Female"])
# if voice_choice != "None":
#     generate_audio(0 if voice_choice == "Male" else 1)
#     st.audio("1.mp3", format='audio/mp3')
# 
# lang_choice = st.selectbox("Choose a Language to Translate:", ["None", "English", "Hindi", "Odia", "Telugu", "Tamil", "Punjabi", "Malayalam", "Marathi"])
# if lang_choice != "None":
#     lang_code = {'English': 'en', 'Hindi': 'hi', 'Odia': 'or', 'Telugu': 'te', 'Tamil': 'ta', 'Punjabi': 'pa', 'Malayalam': 'ml', 'Marathi': 'mr'}[lang_choice]
#     translated_text = change_language(lang_code)
#     st.write(translated_text)
#

!streamlit run /content/app.py & npx localtunnel --port 8501 & curl ipv4.icanhazip.com

!npm install -g localtunnel

!npm audit fix --force



"""## Method-2 Run"""

!pip -q install pyngrok

from pyngrok import ngrok
ngrok.kill()
outh_token='2rwIkDXa1ZbW0FBCVzEfsFVVkcT_29WCU3C6NsMzQGS61MHT1' # we will not provide any token
ngrok.set_auth_token(outh_token)

# create the tunnel
ngrok_tunnel=ngrok.connect(addr="5000",proto="http")
print("Tracking uri:",ngrok_tunnel.public_url)

!streamlit run --server.port 5000 app.py
# !streamlit run --server.port 5000 app.py>/dev/null

